# Image-Processing

ğŸ”¹ Task A â€“ Real vs Synthetic Image Detection
ğŸ“ Task Description

Given an image, predict whether it is:

0 â†’ Real

1 â†’ Synthetic

Two runs are required:

Constrained Run â€“ Only official datasets

Open Run â€“ Any additional external data allowed

ğŸ“‚ Task A Folder Structure
project_directory/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ 0_real/
â”‚   â”‚   â””â”€â”€ 1_fake/
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ 0_real/
â”‚       â””â”€â”€ 1_fake/
â”‚
â”œâ”€â”€ dataset_open/              # Used only for Open Run
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ 0_real/
â”‚   â”‚   â””â”€â”€ 1_fake/
â”‚   â””â”€â”€ val/
â”‚       â”œâ”€â”€ 0_real/
â”‚       â””â”€â”€ 1_fake/
â”‚
â”œâ”€â”€ outputs/
â”œâ”€â”€ submission/
â”‚
â”œâ”€â”€ train.py
â”œâ”€â”€ infer.py
â”œâ”€â”€ submit.py
â”œâ”€â”€ main.py
â”œâ”€â”€ model.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ config_constrained.yaml
â”œâ”€â”€ config_open.yaml

âš™ï¸ Model

Backbone: ConvNext-B

Architecture: CombinedModel (classification branch only)

Training Strategy:

Step 1: Train classifier head

Step 2: Fine-tune last backbone layers

ğŸš€ Task A Commands & Outputs
ğŸ”¸ Training
python main.py --config config_constrained.yaml --action train


Outputs (outputs/):

<run_name>_classifier_model.pth

<run_name>_finetuned_model.pth

<run_name>_val_probs.csv

ğŸ”¸ Inference
python main.py --config config_constrained.yaml --action infer_test \
--ckpt outputs/<run_name>_finetuned_model.pth \
--test_dir data/test


Output:

<run_name>_test_probs.csv


Format:

image_id,prob
img001.jpg,0.823
img002.jpg,0.124

ğŸ”¸ Submission
python main.py --config config_constrained.yaml --action submit


Output:

submission/
â””â”€â”€ teamname_constrained.zip


CSV inside ZIP:

image_id,prob,label,threshold
img001.jpg,0.823,1,0.5
img002.jpg,0.124,0,0.5


Repeat the same process with config_open.yaml for the Open Run.

ğŸ”¹ Task B â€“ Manipulated Region Localization
ğŸ“ Task Description

For each image:

Predict whether it is manipulated (classification)

Predict a pixel-level probability mask indicating manipulated regions

ğŸ“‚ Task B Dataset Structure
Training â€“ TGIF Dataset
TGIF/
â”œâ”€â”€ orig/
â”œâ”€â”€ ps-sp/
â”œâ”€â”€ sd2-sp/
â”œâ”€â”€ sd2-fr/
â”œâ”€â”€ sdxl-fr/
â””â”€â”€ masks/

Validation â€“ COCO + RAISE
validation/
â”œâ”€â”€ coco/
â”‚   â”œâ”€â”€ original/
â”‚   â”œâ”€â”€ brushnet/
â”‚   â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â””â”€â”€ mask/
â”‚   â””â”€â”€ ...
â””â”€â”€ raise/

âš™ï¸ Model

Architecture: CombinedModel (classification + segmentation)

Loss:

Classification â†’ CrossEntropy

Localization â†’ BCE / Dice

Config:

mask_weight: 1.0

ğŸš€ Task B Outputs
ğŸ”¸ Mask Files

One .npz file per test image

Filename must match image name

fEdOddAW3EeT.npz


Contents:

(H, W) float16 array with values in [0.0, 1.0]

ğŸ”¸ scores.csv
image_id,prob,label,threshold,loc_threshold
img001.jpg,0.715,1,0.5,0.5
img002.jpg,0.042,0,0.5,0.5

ğŸ”¸ Submission ZIP
teamname_localization_masks.zip
â”œâ”€â”€ scores.csv
â”œâ”€â”€ img001.npz
â”œâ”€â”€ img002.npz
â””â”€â”€ ...
